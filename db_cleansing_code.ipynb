{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YcanZ-27nzon"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import psycopg2\n",
    "import traceback\n",
    "\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "from sqlalchemy import create_engine, text\n",
    "from psycopg2 import OperationalError, errors\n",
    "from json import loads\n",
    "from io import StringIO\n",
    "\n",
    "# Fungsi untuk membentuk response sukses\n",
    "def build_success_response(data):\n",
    "    return {\n",
    "        'status': 'success',\n",
    "        'message': 'OK',\n",
    "        'code': 'OK',\n",
    "        'trace': 'OK',\n",
    "        'data': data\n",
    "    }\n",
    "\n",
    "# Fungsi untuk membentuk response error dengan struktur tetap\n",
    "def build_error_response(message, exception=None, code=None):\n",
    "    return {\n",
    "        'status': 'error',\n",
    "        'message': f\"{message}\" if exception else message,\n",
    "        'code': code or getattr(exception, 'pgcode', None),\n",
    "        'trace': traceback.format_exc() if exception else None,\n",
    "        'data': None\n",
    "    }\n",
    "\n",
    "# Fungsi utama untuk koneksi dan query\n",
    "def connect_bigdata(schemas, tables):\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname=os.getenv(\"DB_BIGDATA\", \"replikasi****\"),\n",
    "            user=os.getenv(\"DB_USER\", \"pos****\"),\n",
    "            password=os.getenv(\"DB_PASSWORD\", \"2lNyRKW3*****\"),\n",
    "            host=os.getenv(\"DB_HOST\", \"103.****\"),\n",
    "            port=os.getenv(\"DB_PORT\", \"5432\")\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "        query = f'SELECT * FROM \"{schemas}\".\"{tables}\";'\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        df = pd.DataFrame(rows, columns=columns)\n",
    "        return build_success_response(df)\n",
    "\n",
    "    except OperationalError as e:\n",
    "        if \"too many clients\" in str(e):\n",
    "            return build_error_response(\"Terlalu banyak koneksi ke server database. Coba lagi nanti.\", e, code=\"TOO_MANY_CLIENTS\")\n",
    "        return build_error_response(\"Gagal koneksi ke database.\", e, code=\"DB_CONNECT_ERROR\")\n",
    "\n",
    "    except errors.UndefinedTable as e:\n",
    "        return build_error_response(f'Tabel \"{schemas}.{tables}\" tidak ditemukan.', e, code='TABLE_NOT_FOUND')\n",
    "\n",
    "    except errors.UndefinedSchema as e:\n",
    "        return build_error_response(f'Skema \"{schemas}\" tidak ditemukan.', e, code='SCHEMA_NOT_FOUND')\n",
    "\n",
    "    except errors.InsufficientPrivilege as e:\n",
    "        return build_error_response(f'Akses ditolak ke \"{schemas}.{tables}\".', e, code='ACCESS_DENIED')\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        return build_error_response(\"Kesalahan database umum.\", e, code=\"DB_ERROR\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return build_error_response(\"Terjadi error tak terduga saat koneksi.\", e, code=\"UNEXPECTED_ERROR\")\n",
    "\n",
    "    finally:\n",
    "        if cursor: cursor.close()\n",
    "        if conn: conn.close()\n",
    "\n",
    "# Fungsi utama preprocessing\n",
    "def preprocessing(df):\n",
    "    try:\n",
    "        data = df.copy()\n",
    "\n",
    "        # Drop kolom kategori/jumlah jika seluruh nilainya null\n",
    "        if any(c in data.columns for c in [\"kategori\", \"jumlah\"]):\n",
    "            if all(c in data.columns and data[c].isnull().all() for c in [\"kategori\", \"jumlah\"]):\n",
    "                data.drop(columns=[\"kategori\", \"jumlah\"], errors=\"ignore\", inplace=True)\n",
    "            elif \"kategori\" in data.columns and data[\"kategori\"].isnull().all():\n",
    "                data.drop(columns=[\"kategori\"], inplace=True)\n",
    "            elif \"jumlah\" in data.columns and data[\"jumlah\"].isnull().all():\n",
    "                data.drop(columns=[\"jumlah\"], inplace=True)\n",
    "\n",
    "        data.fillna(0, inplace=True)\n",
    "\n",
    "        # data['satuan'] = 'Satuan'\n",
    "        # data['nama_provinsi'] = 'Jawa Timur'\n",
    "        # data['kode_provinsi'] = 35\n",
    "\n",
    "        if 'satuan' not in data.columns:\n",
    "            return build_error_response(f\"Gagal Preprocessing: Kolom 'satuan' tidak ditemukan saat validasi.\", code='SATUAN_NOT_FOUND')\n",
    "\n",
    "        if (data['satuan'].dropna().nunique() == 1 and data['satuan'].isin(['0', '-', 'N/A', 'NA', 'N\\\\A']).all()) or data['satuan'].isna().all():\n",
    "            return build_error_response(f\"Gagal Preprocessing: Kolom 'satuan' null / tidak memiliki value.\", code='SATUAN_IS_NULL')\n",
    "\n",
    "        for del_kode in ['bps_kode_desa_kelurahan', 'bps_kode_kecamatan', 'kemendagri_kode_desa_kelurahan', 'kode_kabupaten_kota', 'kemendagri_kode_kecamatan', 'kode_kecamatan', 'kode_kabupaten', 'kode_kelurahan']:\n",
    "            if del_kode in data.columns:\n",
    "                data.drop(columns=[del_kode], inplace=True)\n",
    "\n",
    "        for col in data.columns:\n",
    "            col_data = data[col]\n",
    "\n",
    "            if col_data.dtype == object:\n",
    "                # print(col)\n",
    "                col_series = col_data.astype(str).str.strip()\n",
    "                col_series = (\n",
    "                    col_series.str.upper()\n",
    "                              .str.replace('_', ' ', regex=False)\n",
    "                              .str.replace('\\\\n', ' ', regex=True)\n",
    "                              .replace(['N/A', 'NA', 'N\\\\A', '-', ''], '0')\n",
    "                )\n",
    "                data[col] = col_series\n",
    "\n",
    "        return build_success_response(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        return build_error_response(f\"Terjadi kesalahan saat preprocessing.\", exception=e, code=\"PREPROCESSING_ERROR\")\n",
    "\n",
    "def periode_update(df):\n",
    "    try:\n",
    "        def standardize_periode(periode):\n",
    "            month_map = {\n",
    "                'JANUARI': '01', 'FEBRUARI': '02', 'MARET': '03', 'APRIL': '04',\n",
    "                'MEI': '05', 'JUNI': '06', 'JULI': '07', 'AGUSTUS': '08',\n",
    "                'SEPTEMBER': '09', 'OKTOBER': '10', 'NOVEMBER': '11', 'DESEMBER': '12'\n",
    "            }\n",
    "            tri_map = {'I': 'Q1', 'II': 'Q2', 'III': 'Q3', 'IV': 'Q4'}\n",
    "            cat_map = {'I': 'C1', 'II': 'C2', 'III': 'C3'}\n",
    "            sem_map = {'I': 'S1', 'II': 'S2'}\n",
    "\n",
    "            if pd.isna(periode) or str(periode).strip() in ['', '-']:\n",
    "                return '0'\n",
    "\n",
    "            periode = str(periode).upper().strip()\n",
    "\n",
    "            # Format: \"dd-mm-yyyy\"\n",
    "            if re.match(r\"\\d{2}-\\d{2}-\\d{4}\", periode):\n",
    "                try:\n",
    "                    return datetime.strptime(periode, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
    "                except:\n",
    "                    return '0'\n",
    "\n",
    "            # Format: \"12 Juli 2025\"\n",
    "            match = re.match(r\"(\\d{1,2})\\s+([A-Z]+)\\s+(\\d{4})\", periode)\n",
    "            if match:\n",
    "                day, month_name, year = match.groups()\n",
    "                month = month_map.get(month_name.upper())\n",
    "                return f\"{year}-{month}-{int(day):02d}\" if month else '0'\n",
    "\n",
    "            # ISO: \"2025-07-12\"\n",
    "            if re.match(r\"\\d{4}-\\d{2}-\\d{2}\", periode):\n",
    "                return periode\n",
    "\n",
    "            year = ['TAHUNAN', 'TAHUN']  # urutkan dari yang lebih panjang agar tidak tumpang tindih\n",
    "\n",
    "            for y in year:\n",
    "                if y in periode:\n",
    "                    return periode.replace(y, '').strip()\n",
    "\n",
    "            # Format: \"JULI 2025\"\n",
    "            for bulan, num in month_map.items():\n",
    "                if bulan in periode:\n",
    "                    tahun_match = re.search(r'\\d{4}', periode)\n",
    "                    return f\"{tahun_match.group()}-{num}\" if tahun_match else '0'\n",
    "\n",
    "            # Format: \"TRIWULAN II 2025\"\n",
    "            if 'TRIWULAN' in periode:\n",
    "                parts = periode.split()\n",
    "                if len(parts) >= 3:\n",
    "                    tahun = re.search(r'\\d{4}', periode)\n",
    "                    if tahun:\n",
    "                        tri = tri_map.get(parts[1], parts[1])\n",
    "                        return f\"{tahun.group()}-{tri}\"\n",
    "\n",
    "            # Format: \"CATURWULAN III 2023\"\n",
    "            if 'CATURWULAN' in periode:\n",
    "                parts = periode.split()\n",
    "                if len(parts) >= 3:\n",
    "                    tahun = re.search(r'\\d{4}', periode)\n",
    "                    if tahun:\n",
    "                        cat = cat_map.get(parts[1], parts[1])\n",
    "                        return f\"{tahun.group()}-{cat}\"\n",
    "\n",
    "            # Format: \"SEMESTER I 2024\"\n",
    "            if 'SEMESTER' in periode:\n",
    "                parts = periode.split()\n",
    "                if len(parts) >= 3:\n",
    "                    tahun = re.search(r'\\d{4}', periode)\n",
    "                    if tahun:\n",
    "                        sem = sem_map.get(parts[1], parts[1])\n",
    "                        return f\"{tahun.group()}-{sem}\"\n",
    "\n",
    "            # Format akhir fallback: \"2023-Q1\", \"2023-S1\", \"2023-C2\"\n",
    "            if any(x in periode for x in ['S1', 'S2', 'Q1', 'Q2', 'Q3', 'Q4', 'C1', 'C2', 'C3']):\n",
    "                tahun_match = re.search(r'\\d{4}', periode)\n",
    "                return periode if tahun_match else '0'\n",
    "\n",
    "            # Ambil tahun saja jika ditemukan\n",
    "            tahun_match = re.search(r'\\d{4}', periode)\n",
    "\n",
    "            return tahun_match.group() if tahun_match else '0'\n",
    "\n",
    "        # Cek kolom sumber\n",
    "        if 'periode_update' in df.columns:\n",
    "            df['periode_update'] = df['periode_update'].astype(str)\n",
    "\n",
    "        elif 'periode' in df.columns:\n",
    "            if 'tahun' in df.columns:\n",
    "                # Jika kolom 'periode' bukan format 4 digit (bukan tahun penuh)\n",
    "                mask = ~df['periode'].astype(str).str.match(r'^\\d{4}$')\n",
    "                if mask.any():\n",
    "                    df['periode_update'] = df['periode'].astype(str) + \" \" + df['tahun'].astype(str)\n",
    "                else:\n",
    "                    df['periode_update'] = df['periode'].astype(str)\n",
    "\n",
    "            else:\n",
    "                df['periode_update'] = df['periode'].astype(str)\n",
    "\n",
    "            df.drop(columns=['periode'], inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "        elif 'tahun' in df.columns:\n",
    "            df['periode_update'] = df['tahun'].astype(str)\n",
    "        else:\n",
    "            return build_error_response(\"Kolom 'periode_update', 'periode', atau 'tahun' tidak ditemukan.\", code=\"PERIODE_COLUMN_NOT_FOUND\")\n",
    "\n",
    "        # Standarisasi nilai\n",
    "        df['periode_update'] = df['periode_update'].apply(standardize_periode)\n",
    "        df['tahun'] = df['periode_update'].str.extract(r'(\\d{4})').fillna(0).astype(int)\n",
    "\n",
    "        # Validasi hasil\n",
    "        if df['periode_update'].isin(['0']).all():\n",
    "            return build_error_response(\"Semua nilai 'periode_update' tidak valid.\", code=\"PERIODE_INVALID_ALL\")\n",
    "\n",
    "        return build_success_response(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        return build_error_response(f\"Terjadi kesalahan saat memproses periode: {str(e)}\", code=\"PERIODE_EXCEPTION\")\n",
    "\n",
    "def deteksi_wilayah(df):\n",
    "    try:\n",
    "\n",
    "      if df is None or df.empty:\n",
    "            raise ValueError(\"DataFrame kosong atau tidak valid.\")\n",
    "\n",
    "      def best_match(target):\n",
    "          return max(df.columns, key=lambda col: SequenceMatcher(None, target, col).ratio())\n",
    "\n",
    "      expected = ['nama_provinsi', 'kabupaten_kota', 'nama_kecamatan', 'desa_kelurahan']\n",
    "      matched = {key: best_match(key) for key in expected}\n",
    "      scores = {key: SequenceMatcher(None, key, matched[key]).ratio() for key in expected}\n",
    "    #   level = sum(score > 0.75 for score in scores.values())\n",
    "\n",
    "      # deteksi eksplisit kolom\n",
    "      kolom = [col.lower() for col in df.columns]\n",
    "      kelurahan = any(k in kolom for k in ['bps_nama_desa_kelurahan', 'kemendagri_nama_desa_kelurahan', 'nama_kelurahan/desa', 'nama_kelurahan', 'nama_desa', 'kelurahan', 'desa'])\n",
    "      kecamatan = any(k in kolom for k in ['kemendagri_nama_kecamatan', 'bps_nama_kecamatan', 'nama_kecamatan', 'kecamatan'])\n",
    "      kabupaten = any(k in kolom for k in ['nama_kabupaten', 'kabupaten', 'kabupaten_kota', 'nama_kabupaten_kota'])\n",
    "      provinsi  = any(k in kolom for k in ['nama_provinsi', 'provinsi', 'prov'])\n",
    "    #   display(level, provinsi, kabupaten, kecamatan, kelurahan, scores, matched)\n",
    "\n",
    "      if provinsi and not (kabupaten or kecamatan or kelurahan):\n",
    "          return build_success_response(('data_provinsi', {'nama_provinsi': matched['nama_provinsi']}))\n",
    "\n",
    "      elif kabupaten and not (kecamatan or kelurahan):\n",
    "          return build_success_response((\n",
    "              'data_kabupaten', {\n",
    "                  'nama_provinsi': matched['nama_provinsi'],\n",
    "                  'nama_kabupaten_kota': matched['kabupaten_kota']\n",
    "              }\n",
    "          ))\n",
    "\n",
    "      elif kecamatan:\n",
    "          return build_success_response((\n",
    "              'data_kecamatan', {\n",
    "                  'nama_provinsi': matched['nama_provinsi'],\n",
    "                  'nama_kabupaten_kota': matched['kabupaten_kota'],\n",
    "                  'bps_nama_kecamatan': matched['nama_kecamatan'],\n",
    "                  'kemendagri_nama_kecamatan': matched['nama_kecamatan']\n",
    "              }\n",
    "          ))\n",
    "\n",
    "      elif kelurahan:\n",
    "          return build_success_response((\n",
    "              'data_kelurahan', {\n",
    "                  'nama_provinsi': matched['nama_provinsi'],\n",
    "                  'nama_kabupaten_kota': matched['kabupaten_kota'],\n",
    "                  'bps_nama_kecamatan': matched['nama_kecamatan'],\n",
    "                  'kemendagri_nama_kecamatan': matched['nama_kecamatan'],\n",
    "                  'bps_desa_kelurahan': matched['desa_kelurahan'],\n",
    "                  'kemendagri_desa_kelurahan': matched['desa_kelurahan']\n",
    "              }\n",
    "          ))\n",
    "\n",
    "      else:\n",
    "          return build_error_response(\"Tidak dapat mendeteksi wilayah dari struktur data yang diberikan.\", code = \"DETECT_LOC_FAILED\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return build_error_response(\"Gagal mendeteksi wilayah.\", exception=e, code = \"DETECT_LOC_ERROR\")\n",
    "\n",
    "def conn_masterdata(status):\n",
    "    \"\"\"\n",
    "    Menghubungkan ke tabel master berdasarkan status wilayah.\n",
    "    Mengembalikan response success dengan dataframe, atau error jika terjadi masalah.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        table_map = {\n",
    "            'data_kabupaten': 'masterkabupaten',\n",
    "            'data_kecamatan': 'masterkecamatan',\n",
    "            'data_kelurahan': 'masterdesa'\n",
    "        }\n",
    "\n",
    "        if status == 'data_provinsi':\n",
    "            return build_success_response(None)  # Tidak perlu tabel master untuk provinsi\n",
    "\n",
    "        table_name = table_map.get(status)\n",
    "\n",
    "        if table_name is None:\n",
    "            return build_error_response(f\"Tidak ditemukan tabel untuk status wilayah: {status}\", code='INVALID_STATUS')\n",
    "\n",
    "        query = f\"SELECT * FROM masterdata.{table_name};\"\n",
    "        db_user = os.getenv(\"DB_USER\", \"postgres\")\n",
    "        db_password = os.getenv(\"DB_PASSWORD\", \"2lNyRKW3oc9kan8n\")\n",
    "        db_host = os.getenv(\"DB_HOST\", \"103.183.92.158\")\n",
    "        db_port = os.getenv(\"DB_PORT\", \"5432\")\n",
    "        db_bigdata_cleaned = os.getenv(\"DB_BIGDATA_CLEANED\", \"result_cleansing\")\n",
    "\n",
    "        engine = create_engine(f\"postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_bigdata_cleaned}\")\n",
    "        datamaster = pd.read_sql(query, engine)\n",
    "\n",
    "        return build_success_response(datamaster)\n",
    "\n",
    "    except Exception as e:\n",
    "        return build_error_response(\"Gagal mengambil data master wilayah.\", exception=e, code=\"MASTERDATA_ERROR\")\n",
    "\n",
    "# hanya untuk data yang terdapat kabupaten kota\n",
    "def format_kabupaten_kota(name):\n",
    "    name = name.upper().strip()  # Pastikan nama dalam huruf besar dan tanpa spasi berlebih\n",
    "    if (name.startswith('KOTA ')):\n",
    "        return name # Jika sudah diawali \"KOTA \", biarkan\n",
    "\n",
    "    elif name.startswith('KABUPATEN '):\n",
    "        return name # Jika sudah diawali \"KABUPATEN \", biarkan\n",
    "\n",
    "    elif name in ['KEDIRI', 'BLITAR', 'MALANG', 'PROBOLINGGO', 'PASURUAN', 'MOJOKERTO', 'MADIUN', 'SURABAYA', 'BATU']:\n",
    "        return f'KOTA {name}'  # Jika nama kota ada di list, tambahkan \"KOTA \" di depannya\n",
    "\n",
    "    elif name.startswith('KAB. '):\n",
    "        return name.replace('KAB. ', 'KABUPATEN ')  # Jika \"KAB. \", ubah menjadi \"KABUPATEN \"\n",
    "\n",
    "    elif name.startswith('0'):\n",
    "        return name  # Jika \"0\", ubah menjadi \"0\"\n",
    "\n",
    "    return f'KABUPATEN {name}'  # Jika tidak, tambahkan \"KABUPATEN {name}\"\n",
    "\n",
    "# hanya untuk data yang terdapat kecamatan\n",
    "def format_kecamatan(name):\n",
    "    name = name.upper().strip()  # Pastikan nama dalam huruf besar dan tanpa spasi berlebih\n",
    "    if name.startswith('KECAMATAN '):\n",
    "        return name.replace('KECAMATAN ', '')  # Jika \"KECAMATAN \", ubah menjadi \"\"\n",
    "\n",
    "    return name\n",
    "\n",
    "# merging df dengan masterdata\n",
    "def merge_df(df, masterdata, left_on_col, right_on):\n",
    "    try:\n",
    "        if df is None or masterdata is None:\n",
    "            return build_error_response(\"Dataframe utama atau masterdata tidak boleh None.\", code ='DATA_NULL')\n",
    "\n",
    "        # Konversi single string ke list\n",
    "        if isinstance(left_on_col, str):\n",
    "            left_on_col = [left_on_col]\n",
    "        if isinstance(right_on, str):\n",
    "            right_on = [right_on]\n",
    "\n",
    "        merged = df.merge(\n",
    "            masterdata,\n",
    "            left_on=left_on_col,\n",
    "            right_on=right_on,\n",
    "            how='left',\n",
    "            suffixes=('_x', '_y')\n",
    "        )\n",
    "\n",
    "        # Hanya drop kolom dari df yang tidak digunakan sebagai join ke masterdata (menghindari kehilangan info penting)\n",
    "        cols_to_drop = [col for col in left_on_col if col not in right_on]\n",
    "        merged.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "        dup_bases = {c[:-2] for c in merged.columns if c.endswith(('_x', '_y'))}\n",
    "        for base in dup_bases:\n",
    "            col_x, col_y = f\"{base}_x\", f\"{base}_y\"\n",
    "\n",
    "            if col_x in merged.columns and col_y in merged.columns:\n",
    "                # Jika punya keduanya: pilih nilai _y; jika NaN pakai _x\n",
    "                merged[base] = merged[col_y].combine_first(merged[col_x])\n",
    "                merged.drop([col_x, col_y], axis=1, inplace=True)\n",
    "\n",
    "            elif col_x in merged.columns:          # hanya _x\n",
    "                merged.rename(columns={col_x: base}, inplace=True)\n",
    "\n",
    "            elif col_y in merged.columns:          # hanya _y\n",
    "                merged.rename(columns={col_y: base}, inplace=True)\n",
    "\n",
    "        return build_success_response(merged)\n",
    "\n",
    "    except Exception as e:\n",
    "        return build_error_response(\n",
    "            message=\"Gagal melakukan merge ke masterdata pada dataframe.\",\n",
    "            exception=e,\n",
    "            code=\"MERGE_ERROR\"\n",
    "        )\n",
    "\n",
    "\n",
    "def check_num(data, col):\n",
    "    df = data.copy()\n",
    "    df.fillna(\"0\", inplace=True)\n",
    "\n",
    "    try:\n",
    "        # --- Pre-clean: hilangkan semua karakter non-numerik (kecuali . , -)\n",
    "        cleaned = (\n",
    "            df[col]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(r'[^0-9\\.,-]', '', regex=True)\n",
    "            .str.replace(r',-$', '', regex=True)\n",
    "            .str.replace(',', '.', regex=True)\n",
    "            .str.replace(r'\\.+', '.', regex=True)  # ubah titik berulang menjadi satu titik\n",
    "            .str.strip('.')\n",
    "        )\n",
    "\n",
    "        # --- Deteksi nilai invalid (kosong atau hanya simbol)\n",
    "        invalid_mask = cleaned.str.fullmatch(r'[.,-]*', na=False)\n",
    "        if invalid_mask.any():\n",
    "            bad_samples = cleaned[invalid_mask].unique()[:3]\n",
    "            return (\n",
    "                \"error\",\n",
    "                f\"Pada kolom '{col}', terdapat {invalid_mask.sum()} nilai tidak valid \"\n",
    "                f\"(kosong atau hanya simbol). Contoh: {bad_samples.tolist()}\"\n",
    "            )\n",
    "\n",
    "        # --- Split berdasarkan titik\n",
    "        split_parts = cleaned.apply(lambda s: [p for p in s.split('.') if p and p.strip() != ''])\n",
    "        num_parts = split_parts.apply(len)\n",
    "        last_len = np.where(\n",
    "            num_parts >= 2,\n",
    "            split_parts.apply(lambda x: len(x[-1]) if isinstance(x, list) and x else 0),\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # --- Validasi format\n",
    "        if (num_parts > 2).any():\n",
    "            bad_mask = num_parts > 2\n",
    "            bad_samples = list(cleaned[bad_mask].unique())\n",
    "\n",
    "            # cek apakah semua contoh berawalan 0. atau -0.\n",
    "            all_small = all(\n",
    "                isinstance(s, str) and re.match(r'^-?0\\.', s.strip())\n",
    "                for s in bad_samples\n",
    "            )\n",
    "\n",
    "            if all_small:\n",
    "                # semua contoh seperti 0.xxx ‚Üí aman\n",
    "                return \"pass\", \"OK\"\n",
    "\n",
    "            return (\n",
    "                \"error\",\n",
    "                f\"Pada kolom '{col}', data memiliki lebih dari 2 simbol parsing (titik/koma). \"\n",
    "                f\"Contoh: {bad_samples[:-3]}\"\n",
    "                f\"\\nData yang bukan desimal tidak perlu ada parsial (titik/koma)\"\n",
    "            )\n",
    "\n",
    "\n",
    "        if ((num_parts <= 2).all()) and (last_len > 2).any():\n",
    "            bad_mask = (num_parts >= 2) & (last_len > 2)\n",
    "            bad_samples = list(cleaned[bad_mask].unique())\n",
    "\n",
    "            # cek apakah semua contoh berawalan 0. atau -0.\n",
    "            all_small = all(\n",
    "                isinstance(s, str) and re.match(r'^-?0\\.', s.strip())\n",
    "                for s in bad_samples\n",
    "            )\n",
    "\n",
    "            if all_small:\n",
    "                # semua contoh seperti 0.xxx ‚Üí aman\n",
    "                return \"pass\", \"OK\"\n",
    "\n",
    "            return (\n",
    "                \"error\",\n",
    "                f\"Pada kolom '{col}', data terindikasi desimal namun memiliki lebih dari 2 digit \"\n",
    "                f\"di belakang koma. Contoh: {bad_samples.tolist()}\"\n",
    "                f\"\\nData desimal harus 2 angka di belakang koma, jika bukan desimal tidak perlu ada parsial (titik/koma)\"\n",
    "            )\n",
    "\n",
    "        if (cleaned.str.contains(r'\\.\\.', regex=True)).any():\n",
    "            bad_samples = cleaned[cleaned.str.contains(r'\\.\\.', regex=True)].unique()[:3]\n",
    "            return (\n",
    "                \"error\",\n",
    "                f\"Pada kolom '{col}', data memiliki dua titik berurutan (format salah). \"\n",
    "                f\"Contoh: {bad_samples.tolist()}\"\n",
    "            )\n",
    "\n",
    "        if cleaned.str.endswith('.').any():\n",
    "            bad_samples = cleaned[cleaned.str.endswith('.')].unique()[:3]\n",
    "            return (\n",
    "                \"error\",\n",
    "                f\"Pada kolom '{col}', beberapa data berakhir dengan titik (kemungkinan salah format). \"\n",
    "                f\"Contoh: {bad_samples.tolist()}\"\n",
    "            )\n",
    "\n",
    "        # --- Jika semua lolos\n",
    "        return \"pass\", \"OK\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"error\", f\"[ERROR] check_num gagal pada kolom '{col}': {e}\"\n",
    "\n",
    "\n",
    "def clean_num(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "\n",
    "    s = str(value).strip()\n",
    "\n",
    "    # --- tangani nilai kosong atau simbol aneh\n",
    "    if s in ['', '-', 'nan', 'NaN', 'None', 'null']:\n",
    "        return np.nan\n",
    "\n",
    "    neg = False\n",
    "    # tanda negatif dalam tanda kurung (misal \"(123)\")\n",
    "    if s.startswith('(') and s.endswith(')'):\n",
    "        neg = True\n",
    "        s = s[1:-1]\n",
    "\n",
    "    # hapus spasi, plus, dan simbol non-numerik\n",
    "    s = s.replace(' ', '').replace('+', '')\n",
    "    s = re.sub(r'[^0-9,.-]', '', s)\n",
    "\n",
    "    # jika kosong setelah dibersihkan\n",
    "    if s in ['', '.', ',', '-']:\n",
    "        return np.nan\n",
    "\n",
    "    # normalisasi desimal\n",
    "    s = s.replace(',', '.')\n",
    "\n",
    "    # ganti titik berurutan menjadi satu titik\n",
    "    s = re.sub(r'\\.+', '.', s)\n",
    "\n",
    "    # hapus titik di awal/akhir\n",
    "    s = s.strip('.')\n",
    "\n",
    "    # jika lebih dari satu titik ‚Üí ambil titik terakhir sebagai desimal\n",
    "    if s.count('.') > 1:\n",
    "        parts = s.split('.')\n",
    "        s = ''.join(parts[:-1]) + '.' + parts[-1]\n",
    "\n",
    "    # jika string berakhir dengan titik ‚Üí buang\n",
    "    if s.endswith('.'):\n",
    "        s = s[:-1]\n",
    "\n",
    "    # ubah ke float\n",
    "    try:\n",
    "        val = float(s)\n",
    "        # bulatkan ke 2 desimal\n",
    "        val = round(val, 2)\n",
    "        # ubah ke int jika tidak punya desimal\n",
    "        if val.is_integer():\n",
    "            val = int(val)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "    return -val if neg else val\n",
    "\n",
    "\n",
    "\n",
    "def transpose_data(df, data_type):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    - df: pandas DataFrame input\n",
    "    - data_type: 'agregat' or 'transaksi'\n",
    "    - clean_numeric_func: function(value) -> float or None ; jika None, pakai pd.to_numeric fallback\n",
    "    - numeric_threshold: proporsi minimal yang harus convertible untuk dianggap numeric (0..1)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = df.copy()\n",
    "\n",
    "        # pastikan ada kolom id (jika tidak ada, buat sebagai string index ‚Äî tapi beri tanda)\n",
    "        if 'id' not in data.columns:\n",
    "            data['id'] = data.index.astype(str)\n",
    "\n",
    "        # daftar kolom identitas wilayah (hanya ambil yang ada di df)\n",
    "        wilayah_cols_map = {\n",
    "            'provinsi': ['kode_provinsi', 'nama_provinsi'],\n",
    "            'kabupaten_kota': ['kode_kabupaten_kota', 'nama_kabupaten_kota'],\n",
    "            'kecamatan': ['bps_kode_kecamatan', 'bps_nama_kecamatan', 'kemendagri_kode_kecamatan', 'kemendagri_nama_kecamatan'],\n",
    "            'desa': ['bps_kode_desa_kelurahan', 'bps_desa_kelurahan', 'kemendagri_kode_desa_kelurahan', 'kemendagri_desa_kelurahan']\n",
    "        }\n",
    "\n",
    "        identitas_wilayah = [c for group in wilayah_cols_map.values() for c in group if c in data.columns]\n",
    "\n",
    "        # kolom exclude dasar (tambahkan identitas wilayah yang ditemukan)\n",
    "        exclude_cols = ['id_index', 'id', 'id_kategori', 'kategori', 'jumlah', 'periode_update', 'satuan', 'periode', 'tahun'] + identitas_wilayah\n",
    "        other_cols = [col for col in data.columns if col not in exclude_cols]\n",
    "\n",
    "        # cek apakah kolom kategori/jumlah ada dan apakah \"kosong\"\n",
    "        def is_col_empty_like(col):\n",
    "            if col not in data.columns:\n",
    "                return True\n",
    "            s = data[col].astype(str).str.strip().replace({'nan': None})\n",
    "            # treat as empty if all null or all token empty or '0'\n",
    "            return s.isin(['None', 'nan', '', '0', 'None']).all()\n",
    "\n",
    "        kategori_exists = 'kategori' in data.columns and not is_col_empty_like('kategori')\n",
    "        jumlah_exists = 'jumlah' in data.columns and not is_col_empty_like('jumlah')\n",
    "\n",
    "        if 'kategori' in data.columns or 'jumlah' in data.columns:\n",
    "            if not kategori_exists and not jumlah_exists:\n",
    "                # drop both if totally empty\n",
    "                data.drop(columns=['kategori', 'jumlah'], errors='ignore', inplace=True)\n",
    "\n",
    "            elif kategori_exists and not jumlah_exists:\n",
    "                if 'kategorikal' not in other_cols:\n",
    "                    # rename kategori -> kategorikal (kategori is categorical)\n",
    "                    data = data.rename(columns={'kategori': 'kategorikal'})\n",
    "                    other_cols.append('kategorikal')\n",
    "\n",
    "                elif 'kategorikal' in other_cols:\n",
    "                    # rename kategori -> kategori_clean (kategori is kategori_clean)\n",
    "                    data = data.rename(columns={'kategori': 'kategori_clean'})\n",
    "                    other_cols.append('kategori_clean')\n",
    "\n",
    "            elif jumlah_exists and not kategori_exists:\n",
    "                # rename jumlah -> total (jumlah numeric)\n",
    "                if 'total' not in other_cols:\n",
    "                    data = data.rename(columns={'jumlah': 'total'})\n",
    "                    other_cols.append('total')\n",
    "\n",
    "                elif 'total' in other_cols:\n",
    "                    data = data.rename(columns={'jumlah': 'jumlah_clean'})\n",
    "                    other_cols.append('jumlah_clean')\n",
    "\n",
    "            elif jumlah_exists and kategori_exists:\n",
    "                if 'kategorikal' not in other_cols:\n",
    "                    data = data.rename(columns={'kategori': 'kategorikal'})\n",
    "                    other_cols.append('kategorikal')\n",
    "\n",
    "                elif 'kategorikal' in other_cols:\n",
    "                    data = data.rename(columns={'kategori': 'kategori_clean'})\n",
    "                    other_cols.append('kategori_clean')\n",
    "\n",
    "                if 'total' not in other_cols:\n",
    "                    data = data.rename(columns={'jumlah': 'total'})\n",
    "                    other_cols.append('total')\n",
    "\n",
    "                elif 'total' in other_cols:\n",
    "                    data = data.rename(columns={'jumlah': 'jumlah_clean'})\n",
    "                    other_cols.append('jumlah_clean')\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        # normalisasi token missing sederhana pada kolom kandidat\n",
    "        tokens_na = ['N/A', 'NA', 'N\\\\A', '-', '']\n",
    "        data[other_cols] = data[other_cols].replace(tokens_na, np.nan)\n",
    "\n",
    "        # --- Deteksi kolom numerik kandidat ---\n",
    "        def convert_ratio(series):\n",
    "            # rasio nilai yang bisa dikonversi ke numeric (before cleaning)\n",
    "            try:\n",
    "                return pd.to_numeric(series, errors='coerce').notna().mean()\n",
    "            except Exception:\n",
    "                return 0.0\n",
    "\n",
    "        # kolom yang sudah numeric dtype\n",
    "        already_numeric = [col for col in other_cols if pd.api.types.is_numeric_dtype(data[col])]\n",
    "\n",
    "        # kolom yang sebagian besar convertible ke numeric (sebelum cleaning)\n",
    "        candidate_num_text = [col for col in other_cols if convert_ratio(data[col]) >= 0.5]\n",
    "\n",
    "        data_df = data.copy()\n",
    "        clean_success = []\n",
    "        err_msg = {}\n",
    "        attempted = []\n",
    "\n",
    "        for col in candidate_num_text:\n",
    "            attempted.append(col)\n",
    "            try:\n",
    "                stat, msg = check_num(data_df, col)\n",
    "\n",
    "                if stat == \"pass\":\n",
    "                    data[col] = data_df[col].apply(clean_num)\n",
    "                    clean_success.append(col)\n",
    "                else:\n",
    "                    err_msg[col] = msg\n",
    "\n",
    "            except Exception as e:\n",
    "                return build_error_response(f\"[ERROR] Gagal memproses kolom '{col}': {e}\", code=\"ERROR_CLEAN_NUMTEXT\")\n",
    "\n",
    "        # final numeric columns (unique)\n",
    "        num_cols_final = list(dict.fromkeys(already_numeric + clean_success))\n",
    "\n",
    "        # kolom yang gagal dibersihkan\n",
    "        error_cols = [col for col in attempted if col not in clean_success]\n",
    "\n",
    "        if error_cols:\n",
    "            first_col, first_err = next(iter(err_msg.items()), (None, None))\n",
    "            return build_error_response(\n",
    "                f\"Data pada kolom numerik {error_cols[:3]} dst. belum bisa dikonversi karena berpotensi ambiguitas data.\\n{first_err}\",\n",
    "                code=\"ERROR_CONVERT_VALUE\"\n",
    "            )\n",
    "\n",
    "        data[num_cols_final] = data[num_cols_final].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        for col in num_cols_final:\n",
    "            non_null = data[col].dropna()\n",
    "            if not non_null.empty and ((non_null.round(6) % 1).abs() < 1e-6).all():\n",
    "                data[col] = data[col].round().astype('Int64')\n",
    "            else:\n",
    "                data[col] = data[col].astype(float)\n",
    "\n",
    "        # cat columns = other_cols minus numeric final\n",
    "        cat_cols = [col for col in other_cols if col not in num_cols_final]\n",
    "\n",
    "        # --- Branch untuk agregat ---\n",
    "        if data_type == 'agregat':\n",
    "            try:\n",
    "                # Jika belum didefinisikan df_melt -> lakukan melt (kebanyakan kasus)\n",
    "                if not ('kategori' in data.columns and 'jumlah' in data.columns):\n",
    "\n",
    "                    id_vars = [col for col in data.columns if col not in num_cols_final + ['kategori', 'jumlah']]\n",
    "                    if not id_vars:\n",
    "                        return build_error_response(\"Tidak ada id_vars untuk melt.\", code=\"MELT_NO_IDVARS\")\n",
    "\n",
    "                    df_melt = data.melt(\n",
    "                        id_vars=id_vars,\n",
    "                        value_vars=num_cols_final,\n",
    "                        var_name='kategori',\n",
    "                        value_name='jumlah'\n",
    "                    )\n",
    "                else:\n",
    "                    # jika kategori & jumlah ada (tidak di-melt), gunakan copy\n",
    "                    df_melt = data.copy()\n",
    "\n",
    "                if df_melt.empty:\n",
    "                    return build_error_response(\n",
    "                        f\"Hasil transpose kosong. Pastikan memiliki kolom numerik yang tepat. Kolom numeric: {num_cols_final}\",\n",
    "                        code=\"MELT_AGGREGATE_FAILED\"\n",
    "                    )\n",
    "\n",
    "                # normalize kategori string\n",
    "                if 'kategori' in df_melt.columns:\n",
    "                    df_melt['kategori'] = df_melt['kategori'].astype(str).str.replace('_', ' ', regex=False)\n",
    "\n",
    "                # uppercase & strip object columns\n",
    "                for col in df_melt.select_dtypes(include='object').columns:\n",
    "                    df_melt[col] = df_melt[col].fillna('0').astype(str).str.strip().str.upper()\n",
    "\n",
    "                # fill remaining NaN untuk konsistensi (tidak wajib)\n",
    "                df_melt.fillna(0, inplace=True)\n",
    "\n",
    "                # order by id then kategori (dense rank)\n",
    "                if 'kategori' in df_melt.columns:\n",
    "                    df_melt['_order'] = df_melt['kategori'].rank(method='dense').astype(int)\n",
    "                else:\n",
    "                    df_melt['_order'] = 0\n",
    "\n",
    "                # reset index, buat id_index incremental (integer)\n",
    "                df_melt = df_melt.reset_index(drop=True).sort_values(['id', '_order'], ignore_index=True).drop(columns=['_order'])\n",
    "                df_melt['id_index'] = (df_melt.index + 1).astype(int)\n",
    "\n",
    "                # build ordered cols, only include cols that exist\n",
    "                agregat_cols = ['periode_update'] + [c for c in cat_cols if c in df_melt.columns] + ['kategori', 'jumlah', 'satuan', 'tahun']\n",
    "                ordered_cols = ['id_index', 'id'] + [c for c in identitas_wilayah if c in df_melt.columns] + [c for c in agregat_cols if c in df_melt.columns]\n",
    "\n",
    "                return build_success_response(df_melt[ordered_cols])\n",
    "\n",
    "            except Exception as e:\n",
    "                return build_error_response(\"Gagal melakukan transposisi data agregat.\", exception=e, code=\"AGGREGATE_TRANSPOSE_ERROR\")\n",
    "\n",
    "        # --- Branch untuk transaksi ---\n",
    "        elif data_type == 'transaksi':\n",
    "            try:\n",
    "                # standardize object cols\n",
    "                for col in data.select_dtypes(include='object').columns:\n",
    "                    data[col] = data[col].fillna('0').astype(str).str.strip().str.upper().str.replace('_', ' ', regex=False)\n",
    "\n",
    "                # if kategori/jumlah actually contain data, ensure they are included\n",
    "                if 'kategorikal' in data.columns:\n",
    "                    if not data['kategorikal'].astype(str).str.strip().isin(['0', '-', 'N/A', 'NA', 'N\\\\A', '']).all():\n",
    "                        data = data.rename(columns={'kategorikal': 'kategori'})\n",
    "                        other_cols.remove('kategorikal')\n",
    "\n",
    "                        if 'kategori' not in other_cols:\n",
    "                            other_cols.append('kategori')\n",
    "\n",
    "                if 'total' in data.columns:\n",
    "                    if not data['total'].astype(str).str.strip().isin(['0', '-', 'N/A', 'NA', 'N\\\\A', '']).all():\n",
    "                        data = data.rename(columns={'total': 'jumlah'})\n",
    "                        other_cols.remove('total')\n",
    "\n",
    "                        if 'jumlah' not in other_cols:\n",
    "                            other_cols.append('jumlah')\n",
    "\n",
    "                # transaksi cols recompute (only existing)\n",
    "                transaksi_cols = [c for c in other_cols if c in data.columns] + [c for c in ['periode_update', 'satuan', 'tahun'] if c in data.columns]\n",
    "\n",
    "                # create safe id_index\n",
    "                data = data.reset_index(drop=True)\n",
    "                data['id_index'] = (data.index + 1).astype(int)\n",
    "\n",
    "                ordered_cols = ['id_index', 'id'] + [c for c in identitas_wilayah if c in data.columns] + transaksi_cols\n",
    "\n",
    "                # ensure columns exist\n",
    "                ordered_cols = [c for c in ordered_cols if c in data.columns]\n",
    "\n",
    "                data.fillna(0, inplace=True)\n",
    "                return build_success_response(data[ordered_cols])\n",
    "\n",
    "            except Exception as e:\n",
    "                return build_error_response(\"Gagal melakukan transposisi data transaksi.\", exception=e, code=\"TRANSACTION_TRANSPOSE_ERROR\")\n",
    "\n",
    "        else:\n",
    "            return build_error_response(\"Jenis data_type tidak valid. Harus 'agregat' atau 'transaksi'.\", code=\"INVALID_DATATYPE\")\n",
    "\n",
    "    except Exception as e:\n",
    "        return build_error_response(\"Terjadi kesalahan umum dalam fungsi transpose_data.\", exception=e, code=\"TRANSPOSE_DATA_ERROR\")\n",
    "\n",
    "\n",
    "def simpan(data, schemas, tables):\n",
    "    try:\n",
    "      # Konversi data ke DataFrame\n",
    "      if isinstance(data, pd.DataFrame):\n",
    "          df = data\n",
    "      elif isinstance(data, str):\n",
    "          try:\n",
    "              df = pd.read_json(StringIO(data))\n",
    "          except Exception as e:\n",
    "              return build_error_response(f\"JSON string tidak valid: {e}\", exception=e, code=\"JSON_SAVE_ERROR\")\n",
    "      elif isinstance(data, (dict, list)):\n",
    "          try:\n",
    "              df = pd.DataFrame(data)\n",
    "          except Exception as e:\n",
    "              return build_error_response(f\"Dictionary tidak bisa dikonversi ke DataFrame: {e}\", exception=e, code=\"DICT_DF_SAVE_FAILED\")\n",
    "      else:\n",
    "          return build_error_response(f\"Input 'data' harus berupa DataFrame, JSON string, atau dictionary.\", exception=e, code=\"DICT_DF_REQ\")\n",
    "\n",
    "      if df is None or df.empty:\n",
    "          return build_error_response(f\"Data Kosong / Terjadi Kesalahan saat Cleansing Sehingga DataFrame Kosong\", code=\"DATA_NULL_SAVE\")\n",
    "\n",
    "      # Deteksi level wilayah dan kolom index\n",
    "      kolom = set(col.lower() for col in df.columns)\n",
    "\n",
    "      opsi_wilayah = [\n",
    "          (['nama_provinsi', 'nama_kabupaten_kota', 'bps_nama_kecamatan', 'bps_nama_desa_kelurahan'], 'data_kelurahan', 'bps_nama_desa_kelurahan'),\n",
    "          (['nama_provinsi', 'nama_kabupaten_kota', 'bps_nama_kecamatan'], 'data_kecamatan', 'bps_nama_kecamatan'),\n",
    "          (['nama_provinsi', 'nama_kabupaten_kota'], 'data_kabupaten', 'nama_kabupaten_kota'),\n",
    "          # (['nama_provinsi'], 'data_provinsi', 'nama_provinsi')\n",
    "      ]\n",
    "\n",
    "      for keys, wilayah, idx in opsi_wilayah:\n",
    "          if all(k in kolom for k in keys):\n",
    "              level_wilayah = wilayah\n",
    "              index_col = idx\n",
    "              break\n",
    "      else:\n",
    "          level_wilayah = None\n",
    "          index_col = None\n",
    "\n",
    "      primary_key = \"id_index\"\n",
    "      tanggal = datetime.now().date()\n",
    "\n",
    "      # Engine SQLAlchemy untuk df.to_sql\n",
    "      db_user = os.getenv(\"DB_USER\", \"postgres\")\n",
    "      db_password = os.getenv(\"DB_PASSWORD\", \"2lNyRKW3oc9kan8n\")\n",
    "      db_host = os.getenv(\"DB_HOST\", \"103.183.92.158\")\n",
    "      db_port = os.getenv(\"DB_PORT\", \"5432\")\n",
    "      db_bigdata_cleaned = os.getenv(\"DB_BIGDATA_CLEANED\", \"result_cleansing\")\n",
    "\n",
    "      engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_bigdata_cleaned}')\n",
    "\n",
    "      # Buat schema dan simpan metadata menggunakan psycopg2\n",
    "      with psycopg2.connect(\n",
    "          dbname=db_bigdata_cleaned,\n",
    "          user=db_user,\n",
    "          password=db_password,\n",
    "          host=db_host,\n",
    "          port=db_port\n",
    "      ) as conn:\n",
    "          with conn.cursor() as cur:\n",
    "              # Buat schema target\n",
    "              cur.execute(f\"CREATE SCHEMA IF NOT EXISTS {schemas};\")\n",
    "              conn.commit()\n",
    "\n",
    "              # Buat schema dan tabel masterdata jika belum ada\n",
    "              cur.execute(\"\"\"\n",
    "                  CREATE SCHEMA IF NOT EXISTS masterdata;\n",
    "                  CREATE TABLE IF NOT EXISTS masterdata.master_jenis_data (\n",
    "                      id BIGINT GENERATED ALWAYS AS IDENTITY PRIMARY KEY,\n",
    "                      nama_schema TEXT,\n",
    "                      nama_table TEXT,\n",
    "                      jenis_data TEXT,\n",
    "                      modified_date DATE\n",
    "                  );\n",
    "              \"\"\")\n",
    "\n",
    "              # Cek apakah metadata sudah ada\n",
    "              cur.execute(\"\"\"\n",
    "                  SELECT id FROM masterdata.master_jenis_data\n",
    "                  WHERE nama_schema = %s AND nama_table = %s;\n",
    "              \"\"\", (schemas, tables))\n",
    "              result = cur.fetchone()\n",
    "\n",
    "              # Deteksi jenis data\n",
    "              cols = df.columns.str.lower()\n",
    "              data_type = 'agregat' if 'kategori' in cols and 'jumlah' in cols else 'transaksi'\n",
    "\n",
    "              if result:\n",
    "                  cur.execute(\"\"\"\n",
    "                      UPDATE masterdata.master_jenis_data\n",
    "                      SET jenis_data = %s, modified_date = %s\n",
    "                      WHERE id = %s;\n",
    "                  \"\"\", (data_type, tanggal, result[0]))\n",
    "                  # print(f\"üîÅ Metadata diperbarui: id={result[0]}\")\n",
    "              else:\n",
    "                  cur.execute(\"\"\"\n",
    "                      INSERT INTO masterdata.master_jenis_data\n",
    "                      (nama_schema, nama_table, jenis_data, modified_date)\n",
    "                      VALUES (%s, %s, %s, %s);\n",
    "                  \"\"\", (schemas, tables, data_type, tanggal))\n",
    "                  # print(f\"‚úÖ Metadata baru disimpan untuk {schemas}.{tables}\")\n",
    "\n",
    "              conn.commit()\n",
    "\n",
    "      # Simpan data utama ke tabel\n",
    "      df.to_sql(\n",
    "          tables,\n",
    "          engine,\n",
    "          schema=schemas,\n",
    "          if_exists='replace',\n",
    "          index=False\n",
    "      )\n",
    "      # print(f\"‚úÖ Data berhasil disimpan ke {schemas}.{tables}.\")\n",
    "\n",
    "      # Tambahkan PRIMARY KEY\n",
    "      parts = tables.split('_')\n",
    "      for i in range(3, len(parts) + 1):\n",
    "          pk_candidate = '_'.join(parts[:i])\n",
    "          pk_constraint = f\"{pk_candidate}_pkey\"\n",
    "          with engine.connect() as con:\n",
    "              existing = con.execute(text(\"\"\"\n",
    "                  SELECT 1 FROM information_schema.table_constraints\n",
    "                  WHERE constraint_schema = :schema AND constraint_name = :name;\n",
    "              \"\"\"), {\"schema\": schemas, \"name\": pk_constraint}).fetchone()\n",
    "\n",
    "              if not existing:\n",
    "                  try:\n",
    "                      con.execute(text(f\"\"\"\n",
    "                          ALTER TABLE {schemas}.{tables}\n",
    "                          ADD CONSTRAINT {pk_constraint} PRIMARY KEY ({primary_key});\n",
    "                      \"\"\"))\n",
    "                      con.commit()\n",
    "                      break\n",
    "                  except Exception:\n",
    "                      break\n",
    "\n",
    "      # Tambahkan index\n",
    "      if index_col:\n",
    "          with engine.connect() as con:\n",
    "              con.execute(text(f\"\"\"\n",
    "                  CREATE INDEX IF NOT EXISTS idx_{tables}_{index_col}\n",
    "                  ON {schemas}.{tables} ({index_col});\n",
    "              \"\"\"))\n",
    "              con.commit()\n",
    "\n",
    "      return build_success_response(f\"Data berhasil disimpan ke {schemas}.{tables}\")\n",
    "\n",
    "    except Exception as e:\n",
    "      return build_error_response(\"Gagal menyimpan data.\", exception=e, code=\"SAVE_ERROR\")\n",
    "\n",
    "def main(schemas, tables, data_type):\n",
    "    try:\n",
    "        # 1. Koneksi Big Data\n",
    "        result = connect_bigdata(schemas, tables)\n",
    "        if result['status'] == 'error':\n",
    "            return result\n",
    "\n",
    "        elif result['status'] == 'success':\n",
    "            # 2. Preprocessing\n",
    "            result = preprocessing(result['data'])\n",
    "\n",
    "            if result['status'] == 'error':\n",
    "                return result\n",
    "\n",
    "            elif result['status'] == 'success':\n",
    "              # 3. Periode Update\n",
    "              result = periode_update(result['data'])\n",
    "              df = result['data']\n",
    "\n",
    "              if result['status'] == 'error':\n",
    "                return result\n",
    "\n",
    "              elif result['status'] == 'success':\n",
    "                # 4. Deteksi Wilayah\n",
    "                result = deteksi_wilayah(result['data'])\n",
    "                # display(result)\n",
    "                status, col_status = result['data']\n",
    "                # display(status, col_status)\n",
    "\n",
    "                # 5. Connect Masterdata\n",
    "                masterdata = conn_masterdata(status)\n",
    "                if masterdata['data'] is not None:\n",
    "                   masterdata = masterdata['data']\n",
    "\n",
    "                if result['status'] == 'error':\n",
    "                  return result\n",
    "\n",
    "                elif result['status'] == 'success':\n",
    "                  # 6.1 Data Kabupaten\n",
    "                  if status == 'data_kabupaten':\n",
    "                    df[col_status['nama_kabupaten_kota']] = df[col_status['nama_kabupaten_kota']].apply(format_kabupaten_kota)\n",
    "                    result = merge_df(\n",
    "                        df,\n",
    "                        masterdata[['kode_kabupaten_kota', 'nama_kabupaten_kota']],\n",
    "                        col_status['nama_kabupaten_kota'],\n",
    "                        'nama_kabupaten_kota'\n",
    "                    )\n",
    "\n",
    "                  # 6.2 Data Kecamatan\n",
    "                  elif status == 'data_kecamatan':\n",
    "                    # 6.2.1 Data Kecamatan Memiliki Kolom Kabupaten\n",
    "                    if col_status['nama_kabupaten_kota'] in ['nama_kabupaten', 'kabupaten', 'kabupaten_kota', 'nama_kabupaten_kota']:\n",
    "                      df[col_status['nama_kabupaten_kota']] = df[col_status['nama_kabupaten_kota']].apply(format_kabupaten_kota)\n",
    "                      df[col_status['bps_nama_kecamatan']] = df[col_status['bps_nama_kecamatan']].apply(format_kecamatan)\n",
    "                      result = merge_df(\n",
    "                          df,\n",
    "                          masterdata[[\n",
    "                              'kode_kabupaten_kota',\n",
    "                              'nama_kabupaten_kota',\n",
    "                              'bps_kode_kecamatan',\n",
    "                              'bps_nama_kecamatan',\n",
    "                              'kemendagri_kode_kecamatan',\n",
    "                              'kemendagri_nama_kecamatan'\n",
    "                          ]],\n",
    "                          [col_status['nama_kabupaten_kota'], col_status['bps_nama_kecamatan']],\n",
    "                          ['nama_kabupaten_kota', 'bps_nama_kecamatan']\n",
    "                      )\n",
    "\n",
    "                    else:\n",
    "                      try:\n",
    "                        df[col_status['bps_nama_kecamatan']] = df[col_status['bps_nama_kecamatan']].apply(format_kecamatan)\n",
    "\n",
    "                        # 6.2.2 Data Kecamatan Tidak Memiliki Kolom Kabupaten pada Schema Kabupaten\n",
    "                        if 'kabupaten' in schemas.lower():\n",
    "                            split = schemas.upper().split('_')\n",
    "                            if len(split) == 2:\n",
    "                              df['nama_kabupaten_kota'] = f'{split[0]} {split[1]}'\n",
    "                              result = merge_df(\n",
    "                              df,\n",
    "                              masterdata[[\n",
    "                                  'kode_kabupaten_kota',\n",
    "                                  'nama_kabupaten_kota',\n",
    "                                  'bps_kode_kecamatan',\n",
    "                                  'bps_nama_kecamatan',\n",
    "                                  'kemendagri_kode_kecamatan',\n",
    "                                  'kemendagri_nama_kecamatan'\n",
    "                              ]],\n",
    "                              ['nama_kabupaten_kota', col_status['bps_nama_kecamatan']],\n",
    "                              ['nama_kabupaten_kota', 'bps_nama_kecamatan'])\n",
    "\n",
    "                            else:\n",
    "                              raise ValueError(\"Melakukan Merge Kecamatan tanpa Kabupaten berisiko duplikasi dengan kecamatan di kabupaten lain\")\n",
    "\n",
    "                        else:\n",
    "                          # 6.2.3 Data Kecamatan Tidak Memiliki Kolom Kabupaten\n",
    "                          result = merge_df(\n",
    "                              df,\n",
    "                              masterdata[[\n",
    "                                  'kode_kabupaten_kota',\n",
    "                                  'nama_kabupaten_kota',\n",
    "                                  'bps_kode_kecamatan',\n",
    "                                  'bps_nama_kecamatan',\n",
    "                                  'kemendagri_kode_kecamatan',\n",
    "                                  'kemendagri_nama_kecamatan'\n",
    "                              ]],\n",
    "                              col_status['bps_nama_kecamatan'],\n",
    "                              'bps_nama_kecamatan')\n",
    "\n",
    "                      except Exception as e:\n",
    "                        return build_error_response('Gagal Merge Kecamatan.', code = 'MERGE_KECAMATAN')\n",
    "\n",
    "                  # 6.3 Data Kelurahan\n",
    "                  elif status == 'data_kelurahan':\n",
    "                      return build_error_response('Proses Data Kelurahan Under Development', code = 'MERGE_KELURAHAN')\n",
    "\n",
    "                  elif status == 'data_provinsi':\n",
    "                    result = build_success_response(df)\n",
    "\n",
    "                  else:\n",
    "                    return build_error_response('Merge Data dengan Status Wilayah', code = 'MERGE_WILAYAH_FAILED')\n",
    "\n",
    "                  if result['status'] == 'error':\n",
    "                    return result\n",
    "\n",
    "                  elif result['status'] == 'success':\n",
    "                    if data_type.lower() == 'agregat':\n",
    "                      # 7.1 Data Agregat\n",
    "                      result = transpose_data(result['data'], 'agregat')\n",
    "\n",
    "                    elif data_type.lower() == 'transaksi':\n",
    "                      # 7.2 Data Transaksi\n",
    "                      result = transpose_data(result['data'], 'transaksi')\n",
    "\n",
    "                    if result['status'] == 'error':\n",
    "                      return result\n",
    "\n",
    "                    elif result['status'] == 'success':\n",
    "                      # 8. Data Result\n",
    "                      data = result['data']\n",
    "                      json_query = data.to_json(orient='records')\n",
    "                      return build_success_response(json_query)\n",
    "    except Exception as e:\n",
    "        return build_error_response(\"Terjadi Kesalahan Umum dalam Cleansing.\", exception=e, code=\"MAIN_ERROR\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOoKnH8xay04n9snnFHfrv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
